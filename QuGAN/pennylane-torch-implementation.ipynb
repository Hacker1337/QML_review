{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from os.path import join\n",
    "import os\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import argparse\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='learns gan on mnist dataset compressed with pca',\n",
    "    formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "parser.add_argument(\n",
    "    '--batch_size',type=int, default=10)\n",
    "parser.add_argument(\"--dimensions\", type=int, default=4,\n",
    "                    help=\"dimension of pca compressed data\")\n",
    "parser.add_argument(\"--epoch\",       default=1,     type=int, help=\"number of epochs to learn\")\n",
    "parser.add_argument(\"--d_lr\",        default=1e-3,  type=float, help=\"learning rate of the discriminator\")\n",
    "parser.add_argument(\"--g_lr\",        default=1e-3,  type=float, help=\"learning rate of the generator\")\n",
    "parser.add_argument(\"--model\",       default=\"q_exp\",   type=str, choices=[\"q_exp\", \"q_sample\", \"c\"],\n",
    "                    help=\"c -- classial GAN,\\n\" +\n",
    "                    \"q_exp -- expectation value base quantum model with classical noise\\n\"+\n",
    "                    \"q_sample -- quantum sample based model. Uses quantum randomness\")\n",
    "parser.add_argument(\"--d_layers\",    default=1,     type=int, help=\"Number of layers of quantum discriminator\")\n",
    "parser.add_argument(\"--g_layers\",    default=1,     type=int, help=\"Number of layers of quantum generator\")\n",
    "parser.add_argument(\"--dataset_size\",default=1000,  type=int,)\n",
    "\n",
    "params, unknown = parser.parse_known_args()\n",
    "if unknown:\n",
    "    print(\"Warning, ignored unknown args:\", *unknown)\n",
    "interactive = False\n",
    "params.dataset_size = min(60_000, params.dataset_size)\n",
    "\n",
    "# #%%\n",
    "# # handmade parameter adjust\n",
    "# params.epoch = 50\n",
    "# params.model = \"q\"\n",
    "# params.d_lr = 1e-2\n",
    "# params.g_lr = 0*1e-3\n",
    "# params.dimensions = 2\n",
    "# params.d_layers = 1\n",
    "# params.g_layers = 9\n",
    "# interactive = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"wandb.env\")\n",
    "wandb.login(key=os.environ[\"WANDB_API_KEY\"])\n",
    "\n",
    "wandb.init(\n",
    "    project=\"QuGAN-mnist\",\n",
    "    notes=\"\",\n",
    "    config=params,\n",
    "    save_code=True,\n",
    ")\n",
    "# wandb.run.log_code(include_fn=lambda path: path.endswith(\"translate_train.ipynb\"))\n",
    "# wandb.run.log_code(\n",
    "#     include_fn=lambda path: path.endswith(\".ipynb\") or path.endswith(\".py\")\n",
    "# )\n",
    "config = wandb.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dimensions = config.dimensions\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = config.batch_size\n",
    "g_lr = config.g_lr\n",
    "d_lr = config.d_lr\n",
    "\n",
    "if config.model == \"q_exp\":\n",
    "    quantum = True\n",
    "    use_noise = True\n",
    "elif config.model == \"q_sample\":\n",
    "    quantum = True\n",
    "    use_noise = False\n",
    "elif config.model == \"c\":\n",
    "    quantum = False\n",
    "\n",
    "# parameters\n",
    "log_step = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create name for data folder\n",
    "\n",
    "time_stamp = datetime.now().strftime(\"%d.%m_%H:%M:%S\")\n",
    "folder = join(\"logs\", f'{config.model}GAN__d={data_dimensions}__{time_stamp}')\n",
    "os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "dataset = datasets.MNIST(root=\"~/.mnist\", train=True, download=True,\n",
    "                         transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = torch.stack([image.flatten() for image, label in dataset])\n",
    "train_labels = torch.tensor([label for image, label in dataset])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# ---------------- PCA Section ---------------------\n",
    "# --------------------------------------------------\n",
    "k = data_dimensions\n",
    "pca = PCA(n_components=k)\n",
    "pca.fit(train_images)\n",
    "pca_data = pca.transform(train_images).astype(np.float32)\n",
    "\n",
    "valid_labels = (train_labels == 3) | (train_labels == 6) | (train_labels == 9)\n",
    "\n",
    "pca_data = pca_data[valid_labels][:config.dataset_size]\n",
    "data_labels = train_labels[valid_labels][:config.dataset_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 10\n",
    "\n",
    "plt.figure(figsize=(4*n_images, 4*2))\n",
    "original_images = train_images[:n_images]\n",
    "\n",
    "plt.suptitle(f\"Real images vs {data_dimensions} dimensions PCA\")\n",
    "for i in range(n_images):\n",
    "    plt.subplot(2, n_images, i+1)\n",
    "    plt.imshow(original_images[i].reshape(28, 28), cmap=\"gray\", vmin=0, vmax=1, interpolation=\"none\")\n",
    "\n",
    "pca.fit(train_images)\n",
    "mixed_images = pca.inverse_transform(pca.transform(original_images))\n",
    "\n",
    "for i in range(n_images):\n",
    "    plt.subplot(2, n_images, n_images + i+1)\n",
    "    plt.imshow(mixed_images[i].reshape(28, 28), cmap=\"gray\", vmin=0, vmax=1, interpolation=\"none\")\n",
    "plt.savefig(join(folder, \"pca_effect\"))\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# --------  Normalize vector components ------------\n",
    "# --------------------------------------------------\n",
    "# scale data to be in [-1, 1]\n",
    "pca_descaler = [[] for _ in range(k)]\n",
    "for i in range(k):\n",
    "    a, b = pca_data[:, i].min(), pca_data[:, i].max(),\n",
    "    pca_descaler[i] = [(a+b)/2, (b-a)/2] # mean, scale\n",
    "    pca_data[:, i] -= pca_descaler[i][0]\n",
    "    pca_data[:, i] /= pca_descaler[i][1]\n",
    "\n",
    "train_dataset = pca_data\n",
    "\n",
    "print(f\"The Total Explained Variance of {k} Dimensions is {sum(pca.explained_variance_ratio_).round(3)}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Define a function that can take in PCA'ed data and return an image\n",
    "# --------------------------------------------------\n",
    "def descale_points(d_point, scales=pca_descaler, tfrm=pca):\n",
    "    for col in range(d_point.shape[1]):\n",
    "        d_point[:, col] *= scales[col][1]\n",
    "        d_point[:, col] += scales[col][0]\n",
    "    reconstruction = tfrm.inverse_transform(d_point)\n",
    "    return reconstruction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if quantum:\n",
    "    # ### Pennylane quantum model\n",
    "\n",
    "    n_qubits = data_dimensions\n",
    "\n",
    "    dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
    "    shot_dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
    "    diff_method = \"adjoint\"\n",
    "\n",
    "    g_params = torch.from_numpy(np.random.uniform(0, 2*np.pi, size=(config.g_layers, 3, n_qubits))).requires_grad_(True)\n",
    "    d_params = torch.from_numpy(np.random.uniform(0, 2*np.pi, size=(config.d_layers, 3, n_qubits))).requires_grad_(True)\n",
    "\n",
    "    def generator_circ(noise, params):\n",
    "        if use_noise:\n",
    "            for i in range(n_qubits):\n",
    "                qml.RX(noise[i], wires=i)\n",
    "\n",
    "        for l in range(config.g_layers):\n",
    "            for i in range(n_qubits):\n",
    "                qml.RY(params[l, 0, i], wires=i)\n",
    "            for i in range(n_qubits):\n",
    "                qml.IsingYY(params[l, 1, i], wires=[i, (i+1) % n_qubits])\n",
    "            for i in range(n_qubits):\n",
    "                qml.CRY(params[l, 2, i], wires=[i, (i+1) % n_qubits])\n",
    "        # todo try with different axes rotations\n",
    "\n",
    "    def data_loading_circ(values):\n",
    "        assert len(values) == n_qubits\n",
    "        assert min(values) >= -1, max(values) <= 1\n",
    "        for i in range(n_qubits):\n",
    "            qml.RY(np.arccos(values[i]), wires=i)\n",
    "\n",
    "    def discriminator(params):\n",
    "        for l in range(config.d_layers):\n",
    "            for i in range(n_qubits):\n",
    "                qml.RY(params[l, 0, i], wires=i)\n",
    "            for i in range(n_qubits):\n",
    "                qml.IsingYY(params[l, 1, i], wires=[i, (i+1) % n_qubits])\n",
    "            for i in range(n_qubits):\n",
    "                qml.CRY(params[l, 2, i], wires=[i, (i+1) % n_qubits])\n",
    "\n",
    "    @qml.qnode(dev, diff_method=diff_method)\n",
    "    def latent_sample(noise, params):\n",
    "        generator_circ(noise, params)\n",
    "        return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "    @qml.qnode(shot_dev,)\n",
    "    def quantum_sample(params):\n",
    "        generator_circ(None, params)\n",
    "        return qml.sample()\n",
    "\n",
    "    @qml.qnode(dev, diff_method=diff_method, interface=\"torch\")\n",
    "    def discriminate_generated_circ(input, real=True):\n",
    "        if real:\n",
    "            data_loading_circ(input)\n",
    "        else:\n",
    "            generator_circ(input, g_params)\n",
    "        qml.adjoint(discriminator)(d_params)\n",
    "        return qml.expval(qml.Hermitian(projector, wires=range(n_qubits)))\n",
    "\n",
    "        # return qml.probs(wires=range(n_qubits))\n",
    "        # + take [0] element when using (but doesn't support adjoint diff)\n",
    "        # and so far throws error \"QuantumFunctionError: Adjoint differentiation method does not support expectation return type mixed with other return types\"\n",
    "\n",
    "    projector = torch.zeros((2**n_qubits, 2**n_qubits))\n",
    "    projector[0, 0] = 1\n",
    "\n",
    "    def discrim_real(data):\n",
    "        '''generates probabilities of discriminating'''\n",
    "        return torch.stack([discriminate_generated_circ(x, real=True)[None] for x in data]).type(data.dtype)\n",
    "\n",
    "    def discrim_fake(z):\n",
    "        '''generates probabilities of discriminating'''\n",
    "        return torch.stack([discriminate_generated_circ(noise, real=False)[None] for noise in z]).type(z.dtype)\n",
    "\n",
    "    def gen_data(noise):\n",
    "        if use_noise:\n",
    "            return [latent_sample(x, g_params) for x in noise]\n",
    "        else:\n",
    "            shots = 20\n",
    "            shot_dev.shots = shots*noise.shape[0]\n",
    "            res = quantum_sample(g_params).reshape(shots, noise.shape[0], n_qubits) \\\n",
    "                .float().mean(axis=0)\n",
    "            res = res*2 - 1  # from [0, 1] to [-1, 1]\n",
    "            return res\n",
    "\n",
    "\n",
    "    d_optimizer = optim.Adam([d_params], lr=d_lr)\n",
    "    g_optimizer = optim.Adam([g_params], lr=g_lr)\n",
    "\n",
    "    latent_size = n_qubits\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "    number_of_generator_params = g_params.numel()\n",
    "    number_of_discriminator_params = d_params.numel()\n",
    "## %%\n",
    "# ### classical model\n",
    "else:\n",
    "    import torch.nn as nn\n",
    "\n",
    "    # Device configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Hyperparameters\n",
    "    image_size = data_dimensions\n",
    "    latent_size = 4\n",
    "    hidden_size = 4\n",
    "\n",
    "    # Generator model\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Generator, self).__init__()\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(latent_size, image_size),\n",
    "                nn.Tanh()  # To ensure pixel values are in the range [-1, 1]\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.model(x)\n",
    "\n",
    "    # Discriminator model\n",
    "    class Discriminator(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Discriminator, self).__init__()\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(image_size, hidden_size),\n",
    "                nn.LeakyReLU(0.02),\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.LeakyReLU(0.02),\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.LeakyReLU(0.02),\n",
    "                nn.Linear(hidden_size, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.model(x)\n",
    "\n",
    "        def predict_real(self, data):\n",
    "            return self.model(data)\n",
    "\n",
    "        def predict_fake(self, noise):\n",
    "            return self.model(self.gen(noise).detach())\n",
    "\n",
    "    # Initialize models and optimizers\n",
    "    generator = Generator().to(device)\n",
    "    discriminator = Discriminator().to(device)\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), lr=d_lr)\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr=g_lr)\n",
    "\n",
    "    def discrim_real(data):\n",
    "        return discriminator(data)\n",
    "\n",
    "    def discrim_fake(noise):\n",
    "        return discriminator(generator(noise))\n",
    "\n",
    "    def gen_data(noise):\n",
    "        return generator(noise)\n",
    "\n",
    "    number_of_generator_params, number_of_discriminator_params = \\\n",
    "    (sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "     for model in [generator, discriminator])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kl_divergance(p, q):\n",
    "    eps = 0.1/p.size    # to be smaller, the uniform proba\n",
    "    p = np.maximum(eps, p)\n",
    "    p /= np.sum(p)\n",
    "    q = np.maximum(eps, q)\n",
    "    q /= np.sum(q)\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def fake_hellinger_distance(p: np.array, q: np.array):\n",
    "    results = []\n",
    "    n = len(p.shape)\n",
    "    for i in range(n):\n",
    "        prior_p = np.sum(p, axis=tuple(range(i)) + tuple(range(i+1, n)))\n",
    "        prior_q = np.sum(q, axis=tuple(range(i)) + tuple(range(i+1, n)))\n",
    "        results.append(hellinger_distance(prior_p, prior_q))\n",
    "    return np.mean(results)\n",
    "\n",
    "def hellinger_distance(p, q):\n",
    "    pointwise_dist =  (np.sqrt(p) - np.sqrt(q))**2\n",
    "    return np.sqrt(np.sum(pointwise_dist)/2)\n",
    "\n",
    "def visualize_discriminator():\n",
    "    assert data_dimensions == 2\n",
    "    n = 10\n",
    "    x = np.linspace(*data_ranges[0], n, dtype=np.float32)\n",
    "    y = np.linspace(*data_ranges[1], n, dtype=np.float32)\n",
    "    grids = np.meshgrid(x, y)\n",
    "    grids = [t.reshape(-1, 1) for t in grids]\n",
    "    xy = np.concatenate(grids, axis=1)\n",
    "    with torch.no_grad():\n",
    "        z = discrim_real(torch.from_numpy(xy))\n",
    "    z = z.reshape((n, n))\n",
    "    full_frame()\n",
    "    plt.contourf(z.T, vmin=0, vmax=1, levels=12)\n",
    "\n",
    "def estimate_density(samples, bins=10):\n",
    "    # Compute the histogram of samples\n",
    "    hist, _ = np.histogramdd(samples, bins=bins, range=data_ranges)\n",
    "    return hist/len(samples)\n",
    "\n",
    "data_ranges = list(zip(np.min(train_dataset, axis=0), np.max(train_dataset, axis=0)))\n",
    "\n",
    "true_dft = estimate_density(train_dataset) # for future computations\n",
    "\n",
    "def fit_multidimensional_normal(data):\n",
    "    # Compute the mean and covariance of the data\n",
    "    mean = np.mean(data, axis=0)\n",
    "    covariance_matrix = np.cov(data, rowvar=False)\n",
    "\n",
    "    # Create a multivariate normal distribution with the computed mean and covariance\n",
    "    fitted_distribution = multivariate_normal(mean=mean, cov=covariance_matrix)\n",
    "\n",
    "    return fitted_distribution\n",
    "\n",
    "def full_frame():\n",
    "    \"\"\"helper function to plot without axis and margins\"\"\"\n",
    "    import matplotlib as mpl\n",
    "    mpl.rcParams['savefig.pad_inches'] = 0\n",
    "    ax = plt.axes([0,0,1,1], frameon=False)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    plt.autoscale(tight=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Learning -------\n",
    "criterion = torch.nn.BCELoss()\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "wandb.run.summary[\"g_params\"] = number_of_generator_params\n",
    "wandb.run.summary[\"d_params\"] = number_of_discriminator_params\n",
    "\n",
    "def get_latent(size):\n",
    "    return torch.randn(size, latent_size).to(device)\n",
    "\n",
    "\n",
    "def fit_epoch():\n",
    "    for i, images in enumerate(train_loader):\n",
    "        batch_size = images.size(0)\n",
    "        images = images.view(batch_size, -1).to(device)\n",
    "\n",
    "        # Create real and fake labels for the loss functions\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # Train the discriminator\n",
    "        # Real images\n",
    "        outputs = discrim_real(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "\n",
    "        # Fake images\n",
    "        z = get_latent(batch_size)\n",
    "        outputs = discrim_fake(z)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "\n",
    "        # Total discriminator loss\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        # Backprop and optimize discriminator\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # Train the generator\n",
    "        z = get_latent(batch_size)\n",
    "        outputs = discrim_fake(z)   # todo check whether it is possible to reuse previous computation ouf this outputs\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "\n",
    "        # Backprop and optimize generator\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        # Print progress\n",
    "        if (i + 1) % log_step == 0:\n",
    "            print(f'Epoch [{epoch+1}/{config.epoch}], Step [{i+1}/{len(train_loader)}], '\n",
    "                  f'Discr Loss: {d_loss.item():.4f}, Gen Loss: {g_loss.item():.4f}')\n",
    "            wandb.log({\"d_loss\": d_loss.item(), \"g_loss\": g_loss.item()})\n",
    "\n",
    "\n",
    "def inference():\n",
    "    # generate images\n",
    "    if quantum and use_noise:\n",
    "        n_samples = 200\n",
    "    else:\n",
    "        n_samples = 2000\n",
    "\n",
    "    points_alpha = min(1, 0.2*1e3/config.dataset_size)\n",
    "    with torch.no_grad():\n",
    "        fake_data = np.array(gen_data(get_latent(n_samples)))\n",
    "\n",
    "    # n_visual = 10\n",
    "    # fake_images = torch.tensor(pca.inverse_transform(fake_data[:n_visual]), dtype=torch.float32)\n",
    "    # # os.makedirs(join(folder, \"gen_images\"), exist_ok=True)\n",
    "    # # save_image(fake_images.view(fake_images.size(0), 1, 28, 28),\n",
    "    # #             join(folder, \"gen_images\", f'generated_images_epoch_{epoch}.jpg'))\n",
    "    # plt.figure(figsize=(2*n_visual, 2))\n",
    "    # for i in range(n_visual):\n",
    "    #     plt.subplot(1, n_visual, i+1)\n",
    "    #     plt.imshow(fake_images[i].view(28, 28), cmap='gray', vmin=0, vmax=1, interpolation=\"none\")\n",
    "    #     plt.axis('off')\n",
    "    # wandb.log({\"generated_images\": wandb.Image(plt)}, commit=False)\n",
    "\n",
    "    # # plt.savefig(join(folder, \"gen_images\", f'my_generated_images_epoch_{epoch}.jpg'))\n",
    "    # plt.close()\n",
    "\n",
    "    # compare distributions on plot\n",
    "\n",
    "    vis_dims = [0, 1]\n",
    "\n",
    "    for l in data_labels.unique():\n",
    "        plt.scatter(pca_data[data_labels == l, vis_dims[0]],\n",
    "                    pca_data[data_labels == l, vis_dims[1]], label=l.item(), c='blue', alpha=points_alpha, s=8)\n",
    "    plt.title(\"PCA values of different images\")\n",
    "    plt.scatter(fake_data[:, vis_dims[0]],\n",
    "                fake_data[:, vis_dims[1]], label=\"fake\", alpha=points_alpha, s=8)\n",
    "\n",
    "    plt.legend(loc='upper right')\n",
    "    wandb.log({\"distributions\":  wandb.Image(plt)}, commit=False)\n",
    "    plt.close()\n",
    "\n",
    "    # plot density function approximation\n",
    "    sampled_data = fake_data[:, vis_dims]\n",
    "\n",
    "    # # normal distribution approximation\n",
    "    # fitted_distribution = fit_multidimensional_normal(sampled_data)\n",
    "    # x, y = np.meshgrid(np.linspace(*data_ranges[vis_dims[0]], 100),\n",
    "    #                    np.linspace(*data_ranges[vis_dims[1]], 100))\n",
    "    # pos = np.dstack((x, y))\n",
    "    # pdf_values = fitted_distribution.pdf(pos)\n",
    "    # plt.contourf(x, y, pdf_values.T, cmap='Reds', alpha=0.7)\n",
    "    # plt.title('2D Density Function of Fitted 2D Normal Distribution')\n",
    "    # wandb.log({\"dft_approx\":  wandb.Image(plt)}, commit=False)\n",
    "    # plt.close()\n",
    "\n",
    "    # handmade hist for full control and contourf plot\n",
    "    full_frame()\n",
    "    pdf_values, edges = np.histogramdd(sampled_data, range=[data_ranges[j] for j in vis_dims], density=True)\n",
    "    plt.contourf(pdf_values.T, cmap='Reds', alpha=0.7,\n",
    "                 extent=[edges[0][0], edges[0][-1], edges[1][0], edges[1][-1]])\n",
    "    # plt.title('Density Function Contourf plot')\n",
    "    for l in data_labels.unique():\n",
    "        plt.scatter(pca_data[data_labels == l, vis_dims[0]],\n",
    "                    pca_data[data_labels == l, vis_dims[1]], label=l.item(), c='blue', alpha=points_alpha, s=8)\n",
    "    plt.legend(loc='upper right')\n",
    "    wandb.log({\"dft_contourf\":  wandb.Image(plt)}, commit=False)\n",
    "    if interactive:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # full_frame()\n",
    "    # # plt.title('Density Function histogram plot')\n",
    "    # plt.hist2d(sampled_data[:, 0], sampled_data[:, 1], range=[data_ranges[j] for j in vis_dims],\n",
    "    #            alpha=0.7, cmap=\"Reds\", bins=15)\n",
    "    # for l in data_labels.unique():\n",
    "    #     plt.scatter(pca_data[data_labels == l, vis_dims[0]],\n",
    "    #                 pca_data[data_labels == l, vis_dims[1]], label=l.item(), c='blue', alpha=points_alpha, s=8)\n",
    "    # plt.legend(loc='upper right')\n",
    "    # wandb.log({\"dft_approx_hist\":  wandb.Image(plt)}, commit=False)\n",
    "    # if interactive:\n",
    "    #     plt.show()\n",
    "    # plt.close()\n",
    "\n",
    "    if data_dimensions == 2:\n",
    "        # visualize discriminator thoughts\n",
    "        visualize_discriminator()\n",
    "        wandb.log({\"disciminator_predictions\":  wandb.Image(plt)}, commit=False)\n",
    "        if interactive:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    # compute metrics\n",
    "    metrics = {}\n",
    "    fake_dft = estimate_density(fake_data)\n",
    "    with torch.no_grad():\n",
    "        metrics[\"kl_divergence\"] = kl_divergance(true_dft, fake_dft).item()\n",
    "        metrics[\"hellinger_distance\"] = hellinger_distance(true_dft, fake_dft).item()\n",
    "        metrics[\"fake_hellinger_distance\"] = fake_hellinger_distance(true_dft, fake_dft).item()\n",
    "        wandb.log(metrics, commit=False)\n",
    "    print(metrics)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(config.epoch):\n",
    "    start = time.time()\n",
    "    # Save generated images each epoch\n",
    "    inference()\n",
    "\n",
    "    print('Time for inference is {} sec'.format(time.time() - start))\n",
    "\n",
    "    start = time.time()\n",
    "    fit_epoch()\n",
    "    print('Time for Epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n",
    "\n",
    "epoch+=1\n",
    "inference()\n",
    "\n",
    "# Save models\n",
    "if quantum:\n",
    "    torch.save(g_params, join(folder, 'generator_model.pth'))\n",
    "    torch.save(d_params, join(folder, 'discriminator_model.pth'))\n",
    "else:\n",
    "    torch.save(generator.state_dict(), join(folder, 'generator_model.pth'))\n",
    "    torch.save(discriminator.state_dict(), join(folder, 'discriminator_model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
