{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NISQ algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QML frameworks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Variable Quantum Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextuality and the inductive bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Recurrent Unit on Gaussian platform\n",
    "\n",
    "Contextual Recurrent Network was proposed in (Anschuetz et al. 2023) as an evolution and development of ideas from (Arute et al. 2019). Arute and others considered k-gram quantum models. They showed, that quantum based modification of Bayesian network performs better, than it's classical counterpart.\n",
    "\n",
    "<!-- ![Performance plots](img/QBayCorrResults.png)\\ -->\n",
    "<img src=img/QBayCorrResults.png width=500>\\\n",
    "Comparison between classical and quantum model from (Arute et al. 2019).\n",
    "\n",
    "This improvement was explained with quantum correlation, which are hard to capture using classical models.\n",
    "Authors also provide a proof of expressive power separation in absolute perfect case. They demonstrate, that classical model with the same parameters won't be able to achieve finite KL divergence, while quantum, due to quantum nonlocality and contextuality, at least in theory is able.\n",
    "\n",
    "Anschuetz et al generalized this proof for neural networks. Quantum model, that they proposed is continuous variable(CV) based. So it is designed to use photonic quantum computer, there instead of every qubit one quantum harmonic oscillator is used.\n",
    "## QRNN architecture\n",
    "For simulation and general simplicity author limit model to only gaussian states. State of CV device can be represented by very difficult nongaussian Wigner quasiprobability function. But initial vacuum state is just a gaussian with zero mean and unit dispersion. So if only gaussian operations are used (operations that transform gaussian to gaussian. e.g. shifting or squeezing), state will keep being gaussian. \n",
    "\n",
    "So if device has $n$ qumods, it's state is fully characterized by vector of means of length $n$ and $n\\times n$ symmetric matrix of covariances. In experiments simulation, that stores these numbers is used.\n",
    "Then evolution of system is described not by specific set of quantum operators (gates), but by general gaussian unitary operation. In fact just square matrix $W$ with size $n+m$ (where n -- hidden state size, and m -- output size). It is the most general gaussian operation, that can be applied to such system. And this matrix is learned with gradient based technic.\n",
    "\n",
    "<img src=img/qrnn_visual.png width=500>\\\n",
    "Authors visualization of model (Anschuetz et al. 2023)\n",
    "\n",
    "To feed the input data to the model, additional $m$ qumods are allocate in quantum device. Input is translated into covariance matrix and means of $m$ qumods via classical fully connected layers. $n$ memory qumod states are also additionally shifted with result of applying another fully connected layer to the input.\n",
    "Finally the hole $n+m$ size system is transformed with $(n+m) \\times (n+m)$ matrix $W$. This mixed memorized information with information obtained on current step.\n",
    "\n",
    "To get output from this model, expectation values on temporal $m$ qumods are measured.\n",
    "\n",
    "\n",
    "As a result QRNN performs in natural language translation task slightly better, than classical models in terms of final KL divergence.\n",
    "<img src=img/qrnn_res.png width=500>\n",
    "\n",
    "Independent implementation of QRNN, is presented in `QRNN` folder. It shows results similar to ones reported by the authors.\n",
    "\n",
    "## Reference\n",
    "Anschuetz, Eric R., Hong-Ye Hu, Jin-Long Huang, and Xun Gao. 2023. “Interpretable Quantum Advantage in Neural Sequence Learning.” PRX Quantum 4 (2): 020338. https://doi.org/10.1103/PRXQuantum.4.020338.\n",
    "\n",
    "Arute, Frank, Kunal Arya, Ryan Babbush, Dave Bacon, Joseph C. Bardin, Rami Barends, Rupak Biswas, et al. 2019. “Quantum Supremacy Using a Programmable Superconducting Processor.” Nature 574 (7779): 505–10. https://doi.org/10.1038/s41586-019-1666-5.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cathegory theory and ZX-calculus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence grammar to Quantum Circuit translation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Graph models review\n",
    "\n",
    "todo insert table with classical datasets results for different models\n",
    "\n",
    "## All subgraphs model\n",
    "\n",
    "All subgraphs quantum graph model for graph classification was introduced in paper \"Graph kernels encoding features of all subgraphs by quantum superposition\" (Kishi et al. 2022). \n",
    "The model is kernel based. It embeds graph into state vector in hilbert space, and than classification is done using standard [SVM kernel trick](https://en.wikipedia.org/wiki/Support_vector_machine). The kernel is just Gram matrix of embeddings in hilbert space. \n",
    "\n",
    "### Graph embedding\n",
    "\n",
    "The main idea is to embed simple properties of a subgraph, like number of vertices or number of edges, into quantum state. Due to properties of quantum computer, qubits can store instantly such information about every subgraph of the embedded graph in the form of superposition.\n",
    "And furthermore, due to linearity of quantum operators this embedding can be evaluated in parallel for all subgraphs. \n",
    "This is called the quantum oracle and this technic is widely used in famous quantum algorithms. In Shor algorithm quantum parallelism is used to raise the same number in multiple powers encoded in superposition to get superposition of the results.\n",
    "$$|0\\rangle + |1\\rangle + |2\\rangle + ... → |a^0\\rangle + |a^1\\rangle + |a^2\\rangle + ...  $$    \n",
    "Likewise in this algorithm exponential speedup is achieved, as computations are done instantly for all $2^{\\#Edges}$ possible subgraphs.\n",
    "\n",
    "In such embedding big scalar product will mean, that graphs have many pairs of subgraphs with the same properties.\n",
    "\n",
    "## Reference:\n",
    "Kishi, Kaito, Takahiko Satoh, Rudy Raymond, Naoki Yamamoto, and Yasubumi Sakakibara. 2022. “Graph Kernels Encoding Features of All Subgraphs by Quantum Superposition.” IEEE Journal on Emerging and Selected Topics in Circuits and Systems 12 (3): 602–13. https://doi.org/10.1109/JETCAS.2022.3200837.\n",
    "\n",
    "## Gaussian Boson Sampling Graph model\n",
    "\n",
    "This graph model was proposed by Xanadu company in (Schuld et al. 2020).\n",
    "Gaussian boson sampling is an analog of the boson sampling circuit, but for optical, or so called continuous variable quantum platform. Boson sampling is mostly famous for being one of the first circuits to demonstrate quantum advantage  (Arute et al. 2019). And it wasn't intended to do something practically useful.\n",
    "\n",
    "![GBS circuit](img/gbs_circuit2.png) \\\n",
    "picture from [pennylane demo](https://pennylane.ai/qml/demos/gbs#id1)\n",
    "\n",
    "In photonic quantum computer each memory/computational unit is not a system with 2 possible energy level, but the quantum harmonic oscillator with countable set of energy levels. And simple family of possible states of each channel is gaussian state. \n",
    "\n",
    "Gaussian boson sampling circuit consist of the input, which is squeezing and displacing of gaussian's states. Then there is constant beam splitters part. And finally in the end numbers of detected photons for each channel is counted ($n_1$, $n_2$, $n_3$, ...)\n",
    "\n",
    "Theory says that probability of getting specific outcome of running GBS circuit is defined by\n",
    "\n",
    "$$P\\left(n_1, n_2 \\ldots n_m\\right)=\\frac{1}{\\operatorname{det}(Q)} \\frac{\\operatorname{Haf}\\left(A_s\\right)}{\\sqrt{n_{1} ! n_{2} ! \\cdots n_{m} !}}$$\n",
    "where all the matrices are defined in terms of the covariance matrix of the gaussian state $\\Sigma$ :\n",
    "\n",
    "$$\n",
    "\\begin{array}{r}\n",
    "Q=\\Sigma+\\mathbb{1} / 2 \\\\\n",
    "A=X\\left(\\mathbb{1}-Q^{-1}\\right) \\\\\n",
    "X=\\left[\\begin{array}{ll}\n",
    "0 & \\mathbb{1} \\\\\n",
    "\\mathbb{1} & 0\n",
    "\\end{array}\\right]\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The $A_s$ matrix is a matrix created from $A$ such that if $n_i=0$, we delete the rows and colums $i$ and $i+m$ of the matrix, and if $n_i \\neq 0$, we repeat the rows and columns $n_i$ times.\n",
    "\n",
    "Hafnian function can be determined mathematically for any symmetric matrix $C$ as\n",
    "\n",
    "$$\n",
    "\\operatorname{haf}(C)=\\sum_{\\pi \\in P_N^{\\{2\\}}} \\prod_{(u, v) \\in \\pi} C_{u, v} .\n",
    "$$\n",
    "Here, $P_N^{\\{2\\}}$ is the set of all $N ! /\\left((N / 2) ! 2^{N / 2}\\right)$ ways to partition the index set $\\{1,2, \\ldots, N\\}$ into $N / 2$ unordered pairs of size 2 , such that each index only appears in one pair. \n",
    "\n",
    "In case of applying GBS for graphs more interesting is case, when C is graph adjacency matrix. This lead to more simple interpretation of hafnian as a number of perfect matchings in the graph G. \n",
    "\n",
    "A perfect matching is a subset of edges such that every node is covered by exactly one of the edges. The Hafnian therefore sums the products of the edge weights in all perfect matchings. If all edge weights are constant, it simply counts the number of perfect matchings in G.\n",
    "\n",
    "Therefore this algorithm uses some meaningful graph property for extracting features from the graph. As hafnian computing is a hard task for classical computer, this gives a potential for quantum supremacy.\n",
    "\n",
    "Finally probabilities of obtaining specific result of gaussian boson sampling are used as a features for SVM kernel to solve classification tasks.\n",
    "\n",
    "\n",
    "## Reference:\n",
    "Schuld, Maria, Kamil Brádler, Robert Israel, Daiqin Su, and Brajesh Gupt. 2020. “Measuring the Similarity of Graphs with a Gaussian Boson Sampler.” Physical Review A 101 (3): 032314. https://doi.org/10.1103/PhysRevA.101.032314.\n",
    "\n",
    "Arute, Frank, Kunal Arya, Ryan Babbush, Dave Bacon, Joseph C. Bardin, Rami Barends, Rupak Biswas, et al. 2019. “Quantum Supremacy Using a Programmable Superconducting Processor.” Nature 574 (7779): 505–10. https://doi.org/10.1038/s41586-019-1666-5.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative models\n",
    "\n",
    "The starting point of using quantum models for generative tasks was done by two articles published together (Dallaire-Demers and Killoran 2018) more practical and (Lloyd and Weedbrook 2018) more theoretical one.\n",
    "\n",
    "Authors claimed that quantum models may have an exponential advantage over classical models.\n",
    "\n",
    "This advantage comes from the fact, that measuring quantum system produces a random sample from exponentially big Hilbert Space.\n",
    "\n",
    "These have more theoretical importance than practical, because sampling itself is rarely used in quantum machine learning. Most approaches (see for example [pennylane demos](https://pennylane.ai/qml/demonstrations/quantum-machine-learning) ) utilize expectation values of output over each qubit. On the one hand expectation value approach doesn't fully explore the potential of quantum computer. For example it fully ignores quantum correlations over different qubits. But on the other hand this approach is more practical. \n",
    "\n",
    "To estimate probabilities of each outcome on real quantum computer, you need exponentially many samples (to keep statistical error $1/\\sqrt{n}$ constant with exponentially increasing number of outcomes). At the same time this makes expectation value more noise resistent, which is vital property in NISQ era. Outcomes themselves are only finite set, while in many practical tasks continuous model prediction (like expectation value) is required.\n",
    "And another significant benefit of expectation value is differentiability. There is a parameter shift technic that replaces infinitely small difference in gradient definition with constant difference. So parameter shift technic makes gradient estimation base on medium number of samples averaging possible. \n",
    "\n",
    "Despite these difficulties, there are several attempts to demonstrate any quantum advantage with generative models on practical tasks.\n",
    "\n",
    "## Molecules generation\n",
    "\n",
    "One of the attempts is done in QuMolGAN paper (Li, Topaloglu, and Ghosh 2021). Authors took classical GAN model for generating molecules MolGAN (N. De Cao, De Cao, and Kipf 2018), and inserted small (2-4 qubit) quantum circuit in the beginning of the generator. After the quantum circuit goes normal classical layers. That's why authors call their model Quantum GAN with hybrid generator.\n",
    "\n",
    "Authors conclude, that their quantum model is more efficient, than classical one. And quantum model can be reduced to only 15% of parameters to show performance comparable with results of nonreduced classical model. \n",
    "\n",
    "During training stage Fréchet distance was measured (see figure below)\n",
    "\n",
    "<img src=img/qumolgan_a_plots.png width=500>\\\n",
    "authors plot with learning of quantum and classical GANs.\n",
    "\n",
    "By dint of code, provided by author, we reproduced model learning.\n",
    "\n",
    "Unfortunately, proper results visualization shows, that there is no significant advantage of quantum model over comparable classical counterpart.\n",
    "\n",
    "In terms of Fréchet distance Quantum Mean Reduced (MR) model shows even worse performance, than Classical MR model, which can be seen on smoothed plots below\n",
    "\n",
    "<img src=img/qumolgan_my_plots.png?0 width=500>\n",
    "\n",
    "Moreover, plot of validity score (fraction of valid molecules from generated) shows, that for all models after certain moment there are only vanishingly few number of valid molecules.\n",
    "\n",
    "<img src=img/qumolgan_my_plots_validity.png width=500>\n",
    "\n",
    "In QuMolGAN quantum part was used as a parameterized quantum circuit (PQC), which means, that expectation values were used as a quantum circuit output. In such configuration output is fully determined by parameters of PQC (angles of qubit rotations). To get any randomness, required for generative model, part of the parameters were replaced with random numbers. In this sense, model work pretty like classical GANs, that just transform input distribution to some distribution similar to target one.\n",
    "\n",
    "Another worth mentioning technic, used in this paper is patching of quantum circuit. \n",
    "\n",
    "To generate random vector of specific size with quantum circuit, this vector is divided into $k$ equal parts. And each part is generated separately with small quantum circuits. This approach gives less expressive, as it is a strong restriction to possible circuits width, and size of used Hilbert space is rather small. But it can be necessary in circumstances of NISQ era with quantum devices strongly limited in number of physical qubits, and with classical simulators limited with number of achievable qubits to simulate. With constant device requirement this technic increases dimensionality of output to values closer to practically applicable. \n",
    "\n",
    "With molecule generation this idea hasn't shown any advantage, but it was successfully applied in earlier work (Huang et al. 2021).\n",
    "\n",
    "## Entire Image Generation\n",
    "\n",
    "<img src=\"img/patched_gan.png\" width=300>\\\n",
    "authors visualization of their model\n",
    "\n",
    "Patch technic was applied to generate raw images of digits without any classical postprocessing. Even with patch simplification, authors had to downscale images to 8x8 pixels.\n",
    "\n",
    "<img src=\"img/101.png\" width=900>\\\n",
    "Authors results of generating 0 and 1 digits.\n",
    "\n",
    "Authors use very simple quantum circuit, and they supply classical random noise to get random output. But remarkably they use probabilities of each outcome as an output. Not expectation values, like in many other works. 5 qubits was used, one of which is ancillary, and 4 output qubits. This gives $2^4=16$ output values. Ancillary qubit gives additional nonlinearity for measured output. As mentioned above, this increases required number of measurements (authors used 3000 samples). But it exponentially increases dimensionality of output data and better unleashes potential of quantum computer.\n",
    "\n",
    "## Compressed images generation\n",
    "\n",
    "In QuGAN paper (Stein et al. 2021) authors compressed digits images to low dimensional (2-4 dimensions) space by principal component analysis (PCA). This makes the task extremely simple, but at the same time more controllable and convenient for experiments.\n",
    "\n",
    "\n",
    "<img src=\"img/real.png\" height=80>\\\n",
    "<img src=\"img/1.png\" height=80>\\\n",
    "<img src=\"img/2.png\" height=80>\\\n",
    "<img src=\"img/3.png\" height=80>\\\n",
    "<img src=\"img/4.png\" height=80>\\\n",
    "<img src=\"img/6.png\" height=80>\\\n",
    "<img src=\"img/10.png\" height=80>\\\n",
    "Demonstration of PCA compression + decompression with different numbers of dimension.\n",
    "\n",
    "<img src=\"img/pca_dist.png\" height=300>\\\n",
    "Distribution of PCA compressed data points (first 2 dimensions)\n",
    "\n",
    "On the picture above you can see visualization of all 10 digits, but only three digits (3,6,9) where used in experiments.\n",
    "\n",
    "### Model architecture\n",
    "In some sense this model is the most quantum among discussed here. It doesn't use classical random noise as an input, but uses quantum random. But they use quantum random in quite specific way.\n",
    "For $n$ dimensional compression $n$ qubit circuit is used. Instead of estimating expectation value over qubits by averaging hight number(~1000) of samples, they average medium (20-30) number of samples. So to certain extend this produces expectation value with significant statistical uncertainty. This results in some distribution. In corner case of 1 sample procedure will result in discrete probability distribution over single measurement outcome ($2^n$ series of \"0\" and \"1\"). Corner case of averaging over $\\inf$ samples results in one real number from [0, 1] over each of $n$ dimensions. \n",
    "Something in between with $m$ samples will result in discrete distribution(binomial distribution) over $m+1$ equally spaced values over each dimension. As it is an averaging of the samples from constant distribution, according to central limit theorem it approaches normal distribution quite fast. \n",
    "This means, that such models won't be able to approximate any complicated distribution far from unimodel \"normal like\" distribution. And furthermore width of distribution (mathematically speaking \"dispersion\") is mostly determined by number of samples. And number as far as it is integer it can't be learned efficiently with gradient decent. \n",
    "\n",
    "Discriminator architecture is also worth mentioning. Discriminator is quantum and represented by another PQC. Discriminator produces $n$ qubits state vector and accesses generator prediction via dot product in Hilbert space. Dot product value is used as a loss function of discriminator and generator. \n",
    "Real data samples are fed to discriminator in the same way after encoding to quantum state. They are encoded by simple single qubit rotations so that expectation values over qubits are equal to true values of data sample.   \n",
    "\n",
    "### Experiments\n",
    "\n",
    "<img src=\"img/pca_author.png\" height=400>\\\n",
    "author's results visualization\n",
    "\n",
    "Authors report significant advantage of quantum model over classical GAN in terms of both number of parameters and visual correctness (see figure above)\n",
    "Source code for quantum model was provided, but due to it's low quality, some error and controversial choice of quantum framework it was reproduced, fixed and complemented by us. Pennylane framework was used instead of qiskit.\n",
    "\n",
    "Code is available in `QuGAN` folder\n",
    "\n",
    "It shows, that with right hyperparameter adjust 20 parameter classical generator can approximate distribution much better, than authors of the article showed.\n",
    "\n",
    "<img src=\"img/dft_contourf_530_c_20_params_id=25.png\" height=300>\\\n",
    "20 parameter classical model results\n",
    "\n",
    "\n",
    "\n",
    "## Reference:\n",
    "Dallaire-Demers, Pierre-Luc, and Nathan Killoran. 2018. “Quantum Generative Adversarial Networks.” Physical Review A 98 (1): 012324. https://doi.org/10.1103/PhysRevA.98.012324.\n",
    "\n",
    "Lloyd, Seth, and Christian Weedbrook. 2018. “Quantum Generative Adversarial Learning.” Physical Review Letters 121 (4): 040502–040502. https://doi.org/10.1103/physrevlett.121.040502.\n",
    "\n",
    "Li, Junde, Rasit Topaloglu, and Swaroop Ghosh. 2021. “(QuMolGAN) Quantum Generative Models for Small Molecule Drug Discovery.” arXiv. http://arxiv.org/abs/2101.03438.\n",
    "\n",
    "N. De Cao, Nicola De Cao, and Thomas Kipf. 2018. “MolGAN: An Implicit Generative Model for Small Molecular Graphs.” ArXiv: Machine Learning, May. https://arxiv.org/abs/1805.11973.\n",
    "\n",
    "Huang, He-Liang, Yuxuan Du, Ming Gong, Youwei Zhao, Yulin Wu, Chaoyue Wang, Shaowei Li, et al. 2021. “Experimental Quantum Generative Adversarial Networks for Image Generation.” Physical Review Applied 16 (2): 024051. https://doi.org/10.1103/PhysRevApplied.16.024051.\n",
    "\n",
    "Stein, Samuel A., Betis Baheri, Daniel Chen, Ying Mao, Qiang Guan, Ang Li, Bo Fang, and Shuai Xu. 2021. “QuGAN: A Quantum State Fidelity Based Generative Adversarial Network.” In 2021 IEEE International Conference on Quantum Computing and Engineering (QCE), 71–81. https://doi.org/10.1109/QCE52317.2021.00023.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
