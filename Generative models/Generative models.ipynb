{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative models\n",
    "\n",
    "The starting point of using quantum models for generative tasks was done by two articles published together (Dallaire-Demers and Killoran 2018) more practical and (Lloyd and Weedbrook 2018) more theoretical one.\n",
    "\n",
    "Authors claimed that quantum models may have an exponential advantage over classical models.\n",
    "\n",
    "This advantage comes from the fact, that measuring quantum system produces a random sample from exponentially big Hilbert Space.\n",
    "\n",
    "These have more theoretical importance than practical, because sampling itself is rarely used in quantum machine learning. Most approaches (see for example [pennylane demos](https://pennylane.ai/qml/demonstrations/quantum-machine-learning) ) utilize expectation values of output over each qubit. On the one hand expectation value approach doesn't fully explore the potential of quantum computer. For example it fully ignores quantum correlations over different qubits. But on the other hand this approach is more practical. \n",
    "\n",
    "To estimate probabilities of each outcome on real quantum computer, you need exponentially many samples (to keep statistical error $1/\\sqrt{n}$ constant with exponentially increasing number of outcomes). At the same time this makes expectation value more noise resistent, which is vital property in NISQ era. Outcomes themselves are only finite set, while in many practical tasks continuous model prediction (like expectation value) is required.\n",
    "And another significant benefit of expectation value is differentiability. There is a parameter shift technic that replaces infinitely small difference in gradient definition with constant difference. So parameter shift technic makes gradient estimation base on medium number of samples averaging possible. \n",
    "\n",
    "Despite these difficulties, there are several attempts to demonstrate any quantum advantage with generative models on practical tasks.\n",
    "\n",
    "## Molecules generation\n",
    "\n",
    "One of the attempts is done in QuMolGAN paper (Li, Topaloglu, and Ghosh 2021). Authors took classical GAN model for generating molecules MolGAN (N. De Cao, De Cao, and Kipf 2018), and inserted small (2-4 qubit) quantum circuit in the beginning of the generator. After the quantum circuit goes normal classical layers. That's why authors call their model Quantum GAN with hybrid generator.\n",
    "\n",
    "Authors conclude, that their quantum model is more efficient, than classical one. And quantum model can be reduced to only 15% of parameters to show performance comparable with results of nonreduced classical model. \n",
    "\n",
    "During training stage Fréchet distance was measured (see figure below)\n",
    "\n",
    "<img src=https://raw.githubusercontent.com/Hacker1337/QML_review/f27334cc67f0675854cfce04df67f6facd5b95de/img/qumolgan_a_plots.png width=500>\\\n",
    "authors plot with learning of quantum and classical GANs.\n",
    "\n",
    "By dint of code, provided by author, we reproduced model learning.\n",
    "\n",
    "Unfortunately, proper results visualization shows, that there is no significant advantage of quantum model over comparable classical counterpart.\n",
    "\n",
    "In terms of Fréchet distance Quantum Mean Reduced (MR) model shows even worse performance, than Classical MR model, which can be seen on smoothed plots below\n",
    "\n",
    "<img src=https://raw.githubusercontent.com/Hacker1337/QML_review/f27334cc67f0675854cfce04df67f6facd5b95de/img/qumolgan_my_plots.png?0 width=500>\n",
    "\n",
    "Moreover, plot of validity score (fraction of valid molecules from generated) shows, that for all models after certain moment there are only vanishingly few number of valid molecules.\n",
    "\n",
    "<img src=https://raw.githubusercontent.com/Hacker1337/QML_review/f27334cc67f0675854cfce04df67f6facd5b95de/img/qumolgan_my_plots_validity.png width=500>\n",
    "\n",
    "In QuMolGAN quantum part was used as a parameterized quantum circuit (PQC), which means, that expectation values were used as a quantum circuit output. In such configuration output is fully determined by parameters of PQC (angles of qubit rotations). To get any randomness, required for generative model, part of the parameters were replaced with random numbers. In this sense, model work pretty like classical GANs, that just transform input distribution to some distribution similar to target one.\n",
    "\n",
    "Another worth mentioning technic, used in this paper is patching of quantum circuit. \n",
    "\n",
    "To generate random vector of specific size with quantum circuit, this vector is divided into $k$ equal parts. And each part is generated separately with small quantum circuits. This approach gives less expressive, as it is a strong restriction to possible circuits width, and size of used Hilbert space is rather small. But it can be necessary in circumstances of NISQ era with quantum devices strongly limited in number of physical qubits, and with classical simulators limited with number of achievable qubits to simulate. With constant device requirement this technic increases dimensionality of output to values closer to practically applicable. \n",
    "\n",
    "With molecule generation this idea hasn't shown any advantage, but it was successfully applied in earlier work (Huang et al. 2021).\n",
    "\n",
    "## Entire Image Generation\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hacker1337/QML_review/f27334cc67f0675854cfce04df67f6facd5b95de/img/patched_gan.png\" width=300>\\\n",
    "authors visualization of their model\n",
    "\n",
    "Patch technic was applied to generate raw images of digits without any classical postprocessing. Even with patch simplification, authors had to downscale images to 8x8 pixels.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hacker1337/QML_review/f27334cc67f0675854cfce04df67f6facd5b95de/img/101.png\" width=900>\\\n",
    "Authors results of generating 0 and 1 digits.\n",
    "\n",
    "Authors use very simple quantum circuit, and they supply classical random noise to get random output. But remarkably they use probabilities of each outcome as an output. Not expectation values, like in many other works. 5 qubits was used, one of which is ancillary, and 4 output qubits. This gives $2^4=16$ output values. Ancillary qubit gives additional nonlinearity for measured output. As mentioned above, this increases required number of measurements (authors used 3000 samples). But it exponentially increases dimensionality of output data and better unleashes potential of quantum computer.\n",
    "\n",
    "## Compressed images generation\n",
    "\n",
    "In QuGAN paper (Stein et al. 2021) authors compressed digits images to low dimensional (2-4 dimensions) space by principal component analysis (PCA). This makes the task extremely simple, but at the same time more controllable and convenient for experiments.\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hacker1337/QML_review/f27334cc67f0675854cfce04df67f6facd5b95de/img/real.png\" height=80>\\\n",
    "<img src=\"https://raw.githubusercontent.com/Hacker1337/QML_review/f27334cc67f0675854cfce04df67f6facd5b95de/img/1.png\" height=80>\\\n",
    "<img src=\"https://raw.githubusercontent.com/Hacker1337/QML_review/f27334cc67f0675854cfce04df67f6facd5b95de/img/2.png\" height=80>\\\n",
    "<img src=\"https://raw.githubusercontent.com/Hacker1337/QML_review/f27334cc67f0675854cfce04df67f6facd5b95de/img/3.png\" height=80>\\\n",
    "<img src=\"https://raw.githubusercontent.com/Hacker1337/QML_review/f27334cc67f0675854cfce04df67f6facd5b95de/img/4.png\" height=80>\\\n",
    "<img src=\"https://raw.githubusercontent.com/Hacker1337/QML_review/f27334cc67f0675854cfce04df67f6facd5b95de/img/6.png\" height=80>\\\n",
    "<img src=\"https://raw.githubusercontent.com/Hacker1337/QML_review/f27334cc67f0675854cfce04df67f6facd5b95de/img/10.png\" height=80>\\\n",
    "Demonstration of PCA compression + decompression with different numbers of dimension.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hacker1337/QML_review/f27334cc67f0675854cfce04df67f6facd5b95de/img/pca_dist.png\" height=300>\\\n",
    "Distribution of PCA compressed data points (first 2 dimensions)\n",
    "\n",
    "On the picture above you can see visualization of all 10 digits, but only three digits (3,6,9) where used in experiments.\n",
    "\n",
    "### Model architecture\n",
    "In some sense this model is the most quantum among discussed here. It doesn't use classical random noise as an input, but uses quantum random. But they use quantum random in quite specific way.\n",
    "For $n$ dimensional compression $n$ qubit circuit is used. Instead of estimating expectation value over qubits by averaging hight number(~1000) of samples, they average medium (20-30) number of samples. So to certain extend this produces expectation value with significant statistical uncertainty. This results in some distribution. In corner case of 1 sample procedure will result in discrete probability distribution over single measurement outcome ($2^n$ series of \"0\" and \"1\"). Corner case of averaging over $\\inf$ samples results in one real number from [0, 1] over each of $n$ dimensions. \n",
    "Something in between with $m$ samples will result in discrete distribution(binomial distribution) over $m+1$ equally spaced values over each dimension. As it is an averaging of the samples from constant distribution, according to central limit theorem it approaches normal distribution quite fast. \n",
    "This means, that such models won't be able to approximate any complicated distribution far from unimodel \"normal like\" distribution. And furthermore width of distribution (mathematically speaking \"dispersion\") is mostly determined by number of samples. And number as far as it is integer it can't be learned efficiently with gradient decent. \n",
    "\n",
    "Discriminator architecture is also worth mentioning. Discriminator is quantum and represented by another PQC. Discriminator produces $n$ qubits state vector and accesses generator prediction via dot product in Hilbert space. Dot product value is used as a loss function of discriminator and generator. \n",
    "Real data samples are fed to discriminator in the same way after encoding to quantum state. They are encoded by simple single qubit rotations so that expectation values over qubits are equal to true values of data sample.   \n",
    "\n",
    "### Experiments\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hacker1337/QML_review/f27334cc67f0675854cfce04df67f6facd5b95de/img/pca_author.png\" height=400>\\\n",
    "author's results visualization\n",
    "\n",
    "Authors report significant advantage of quantum model over classical GAN in terms of both number of parameters and visual correctness (see figure above)\n",
    "Source code for quantum model was provided, but due to it's low quality, some error and controversial choice of quantum framework it was reproduced, fixed and complemented by us. Pennylane framework was used instead of qiskit.\n",
    "\n",
    "Code is available in `QuGAN` folder\n",
    "\n",
    "It shows, that with right hyperparameter adjust 20 parameter classical generator can approximate distribution much better, than authors of the article showed.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hacker1337/QML_review/f27334cc67f0675854cfce04df67f6facd5b95de/img/dft_contourf_530_c_20_params_id=25.png?0\" height=300>\\\n",
    "20 parameter classical model results\n",
    "\n",
    "All results are available in wandb platform https://wandb.ai/amirfvb/QuGAN-mnist\n",
    "\n",
    "\n",
    "## Reference:\n",
    "Dallaire-Demers, Pierre-Luc, and Nathan Killoran. 2018. “Quantum Generative Adversarial Networks.” Physical Review A 98 (1): 012324. https://doi.org/10.1103/PhysRevA.98.012324.\n",
    "\n",
    "Lloyd, Seth, and Christian Weedbrook. 2018. “Quantum Generative Adversarial Learning.” Physical Review Letters 121 (4): 040502–040502. https://doi.org/10.1103/physrevlett.121.040502.\n",
    "\n",
    "Li, Junde, Rasit Topaloglu, and Swaroop Ghosh. 2021. “(QuMolGAN) Quantum Generative Models for Small Molecule Drug Discovery.” arXiv. http://arxiv.org/abs/2101.03438.\n",
    "\n",
    "N. De Cao, Nicola De Cao, and Thomas Kipf. 2018. “MolGAN: An Implicit Generative Model for Small Molecular Graphs.” ArXiv: Machine Learning, May. https://arxiv.org/abs/1805.11973.\n",
    "\n",
    "Huang, He-Liang, Yuxuan Du, Ming Gong, Youwei Zhao, Yulin Wu, Chaoyue Wang, Shaowei Li, et al. 2021. “Experimental Quantum Generative Adversarial Networks for Image Generation.” Physical Review Applied 16 (2): 024051. https://doi.org/10.1103/PhysRevApplied.16.024051.\n",
    "\n",
    "Stein, Samuel A., Betis Baheri, Daniel Chen, Ying Mao, Qiang Guan, Ang Li, Bo Fang, and Shuai Xu. 2021. “QuGAN: A Quantum State Fidelity Based Generative Adversarial Network.” In 2021 IEEE International Conference on Quantum Computing and Engineering (QCE), 71–81. https://doi.org/10.1109/QCE52317.2021.00023.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
