{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QML frameworks\n",
    "\n",
    "There are two most popular frameworks for quantum machine learning: pennylane (Bergholm et al. 2022) by Xanadu and TensorFlow Quantum (Broughton et al. 2021) from Google. There is also popular qiskit (Aleksandrowicz et al. 2019) framework from IBM, designed more for general quantum computing than for quantum machine learning, but it can also be used for ML (see for example [qiskit QML tutorials](https://qiskit.org/ecosystem/machine-learning/tutorials/index.html)).\n",
    "\n",
    "In general these frameworks provide:\n",
    "- interface for defining quantum circuits\n",
    "- classical simulators of quantum circuits for easy small scale noiseless experiments\n",
    "- interface for running circuits on real quantum hardware by different providers\n",
    "- interface for seamless integration with classical machine learning frameworks (Pytorch and Tensorflow), which allow:\n",
    "  - integration of quantum models to existing ML pipelines\n",
    "  - constructing hybrid quantum/classical model\n",
    "\n",
    "\n",
    "Except for fast circuit result prediction, ML tasks usually require efficient ways of gradients estimating. There are several popular derivative counting algorithms suitable for simulation or for real quantum hardware\n",
    "\n",
    "### Finite difference\n",
    "This is the simples default technic available both in simulation and on hardware. Works pretty bed with sampling based methods due to significant noise.\n",
    "\n",
    "Can be expressed as:\n",
    "\n",
    "\n",
    "$$\\nabla_{\\theta_i}\\mathcal{M}_{\\theta_i}(\\hat{B}) = \\frac{[\\mathcal{M}_{\\theta_i + d\\theta}(\\hat{B}) - \\mathcal{M}_{\\theta_i}(\\hat{B})]}{d\\theta}$$\n",
    "\n",
    "or as\n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\alpha} f(\\alpha) = \\frac{1}{d\\alpha} \\cdot \\left( f\\left(\\alpha + d\\alpha\\right) -  f\\left(\\alpha \\right) \\right)  $$\n",
    "\n",
    "### Parameter shift\n",
    "Parameter shifting rule is much more noise resistent technic compatible with sampling. \n",
    "It was first introduced to quantum machine learning in [Mitarai et al. (2018)](https://arxiv.org/abs/1803.00745 \"‌\"), and extended in [Schuld et al. (2018)](https://arxiv.org/abs/1811.11184 \"‌\").\n",
    "\n",
    "In these works it was proved, that for any one qubit gate such a wonder full property is fulfilled. For these gates exist finite constants $с$ and $s$ that\n",
    "\n",
    "$$\\nabla_{\\theta_i}\\mathcal{M}_{\\theta_i}(\\hat{B}) = c[\\mathcal{M}_{\\theta_i + s}(\\hat{B}) - \\mathcal{M}_{\\theta_i - s}(\\hat{B})],$$\n",
    "which means that infinitely small difference can be replaced with some specific big difference, but equality will still hold.\n",
    "\n",
    "For example for PauliY gate \\\n",
    "$|\\alpha⟩ = Y^{\\alpha}|0⟩$ \\\n",
    "$f(\\alpha) = ⟨\\alpha|X|\\alpha⟩$\n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\alpha} f(\\alpha) = \\frac{\\pi}{2} f\\left(\\alpha + \\frac{1}{2}\\right) -  \\frac{ \\pi}{2} f\\left(\\alpha - \\frac{1}{2}\\right)$$\n",
    "\n",
    "## Simulation technics\n",
    "Since simulators play important role in research process, tricks that improve algorithm running speed only in simulation were also developed, although they will loose their significance in post NISQ era.\n",
    "\n",
    "### Adjoint method\n",
    "Detailed tutorial with theory explanations can be found in [demo](https://pennylane.ai/qml/demos/tutorial_adjoint_diff.html) from pennyLane.\n",
    "\n",
    "But in a nutshell this method accelerate gradient evaluation by exploiting reversibility of quantum operations. While inverse matrix computation in general is relatively slow, for unitary matrix representing quantum operations by definition inverse equals to adjoint (transposition + complex conjugate) with is almost computationally free.\n",
    "\n",
    "Considering this, algorithm is as follows:\n",
    "\n",
    "$$\\langle M \\rangle = \\langle b | k \\rangle = \\langle \\Psi | M | \\Psi \\rangle$$\n",
    "\n",
    "Firstly decompose the expectation into the scalar product of two vectors\n",
    "\n",
    "$$\\langle b | = \\langle \\Psi| M = \\langle 0 | U_0^{\\dagger} \\dots U_n^{\\dagger} M$$\n",
    "$$| k \\rangle =  |\\Psi \\rangle = U_n U_{n-1} \\dots U_0 |0\\rangle$$\n",
    "\n",
    "change the location of the partition by transferring the matrices in turn from one vector to another.\n",
    "\n",
    "$$\\langle b_i | = \\langle 0 | U_1^{\\dagger} \\dots U_n^{\\dagger} M U_n \\dots U_{i+1}$$\n",
    "$$|k_i \\rangle = U_{i-1} \\dots U_1 |0\\rangle$$\n",
    "\n",
    "$$\\langle b_i | = \\langle b_{i+1}| U_{i}$$\n",
    "$$|k_{i} \\rangle = U_{i+1}^{\\dagger} |k_{i+1}\\rangle$$\n",
    "\n",
    "To calculate the derivative, the matrix derivative with respect to the parameter is inserted into the required partition.\n",
    "\n",
    "$$\\langle 0 | U_1^{\\dagger} \\dots U_i^{\\dagger} \\dots M \\dots \\frac{\\text{d} U_i}{\\text{d} \\theta_i}  \\dots U_1 |0\\rangle$$\n",
    "$$= \\langle b_i | \\frac{\\text{d} U_i}{\\text{d} \\theta_i} |k_i \\rangle$$\n",
    "\n",
    "\n",
    "<img src=\"https://pennylane.ai/_images/scaling.png\" width=800>\\\n",
    "benchmark results from pennylane demo\n",
    "\n",
    "Both pennylane and tf quantum provide fast adjoint simulation and the overall performance in best configuration is almost the same. This is demonstrated by our tests (see plot below). Source code for benchmarks reproducing is located in `qml_frameworks_benchmarking`\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Hacker1337/QML_review/f27334cc67f0675854cfce04df67f6facd5b95de/img/benchmarks.png\" width=400>\\\n",
    "frameworks speed comparison.\n",
    "\n",
    "## Closing remark\n",
    "These frameworks are also able to simulate realistic noise, they are compatible with wide range of quantum hardware providers (see table below for comparison)\n",
    "\n",
    "\n",
    "| **Company**                 | **TensorFlow(cirq) support** | **PennyLane Support** | **# qubits** |\n",
    "|-----------------------------|------------------------------|-----------------------|--------------|\n",
    "| IBM                         | - ([link 2020](https://quantumcomputing.stackexchange.com/questions/14164/can-i-run-cirq-on-ibmq))| +                     | 127(up to 7 free)|\n",
    "| Amazon Braket               |                              | +                     |              |\n",
    "| Google(Cirq)                | +                            | +                     | 53           |\n",
    "| Microsoft                   | +                            | +                     | ?            |\n",
    "| Honeywell (Quantinuum)      |                              | +                     | 20           |\n",
    "| IonQ                        | +                            | +                     | 34           |\n",
    "| Alpine Quantum Technologies | +                            | +                     |              |\n",
    "| Rigetti                     | +                            | +                     | 80           |\n",
    "| Pasqal                      | +                            | +(through cirq)       | 100          |\n",
    "| Xanadu                      |                              | +                     | 200+         |\n",
    "\n",
    "Although these frameworks are pretty similar,  there is one notable difference. The hallmark of Pennylane is the support of Continuous Variable quantum computing, which is a topic of the next section. \n",
    "\n",
    "\n",
    "## Reference\n",
    "\n",
    "Aleksandrowicz, Gadi, Thomas Alexander, Panagiotis Barkoutsos, Luciano Bello, Yael Ben-Haim, David Bucher, Francisco Jose Cabrera-Hernández, et al. 2019. “Qiskit: An Open-Source Framework for Quantum Computing.” Zenodo. https://doi.org/10.5281/zenodo.2562111.\n",
    "\n",
    "Bergholm, Ville, Josh Izaac, Maria Schuld, Christian Gogolin, Shahnawaz Ahmed, Vishnu Ajith, M. Sohaib Alam, et al. 2022. “PennyLane: Automatic Differentiation of Hybrid Quantum-Classical Computations.” arXiv. https://doi.org/10.48550/arXiv.1811.04968.\n",
    "\n",
    "Broughton, Michael, Guillaume Verdon, Trevor McCourt, Antonio J. Martinez, Jae Hyeon Yoo, Sergei V. Isakov, Philip Massey, et al. 2021. “TensorFlow Quantum: A Software Framework for Quantum Machine Learning.” arXiv. https://doi.org/10.48550/arXiv.2003.02989.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
